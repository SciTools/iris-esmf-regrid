# Use ASV to check for performance regressions, either:
#  - In the last 24 hours' commits.
#  - Introduced by this pull request.

name: benchmarks-run
run-name: Run benchmarks

on:
  pull_request:

  push:
    branches:
      - "main"
      - "v*x"
      - "!auto-update-lockfiles"
      - "!pre-commit-ci-update-config"
      - "!dependabot/*"
    tags:
      - "v*"

  workflow_dispatch:

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  benchmark:
    runs-on: ubuntu-latest

    env:
      PY_VER: "3.12"
      IRIS_TEST_DATA_LOC_PATH: benchmarks
      IRIS_TEST_DATA_PATH: benchmarks/iris-test-data
      IRIS_TEST_DATA_VERSION: "2.19"
      #: If you change the IRIS_SOURCE here you will also need to change it in
      #:  the noxfile and the tests and wheel workflows.
      IRIS_SOURCE: "github:main"
      # Lets us manually bump the cache to rebuild
      ENV_CACHE_BUILD: "0"
      TEST_DATA_CACHE_BUILD: "0"

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install ASV & Nox
        run: pip install asv nox

      - name: Cache environment directories
        id: cache-env-dir
        uses: actions/cache@v4
        with:
          path: |
            .nox
            benchmarks/.asv/env
            $CONDA/pkgs
          key: ${{ runner.os }}-${{ hashFiles('requirements/locks/') }}-${{ env.ENV_CACHE_BUILD }}-${{ env.IRIS_SOURCE }}

      - name: Benchmark this pull request
        run: |
          if ${{ github.event_name != 'pull_request' }}; then export COMPARE="HEAD~"; else export COMPARE="origin/${{ github.base_ref }}"; fi;
          python benchmarks/bm_runner.py branch ${COMPARE}

      - name: Archive asv results
        # Store the raw ASV database(s) to help manual investigations.
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: asv-raw-results
          path: benchmarks/.asv/results
